# -*- coding: utf-8 -*-
"""NewsClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lM6yMo6iApZDtKMKKxmB7JeFV4v3VvDS
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import LabelEncoder
import re

df = pd.read_csv('test.csv')
df = df.dropna()

def clean(text):
  text = str(text).lower()
  text = re.sub(r"[^a-z0-9\s]", " ", text)
  return " ".join(text.split())
df['clean_text'] = df['text'].apply(clean)

label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['label'])
num_classes = len(label_encoder.classes_)

MAX_VOCAB = 10000
SEQ_LEN = 40
BATCH = 32

vectorizer = layers.TextVectorization(max_tokens = MAX_VOCAB, output_sequence_length = SEQ_LEN)
vectorizer.adapt(df['clean_text'])

train_texts = df['clean_text'].values
train_labels = df['label'].values

train_ds = tf.data.Dataset.from_tensor_slices((train_texts, train_labels))
train_ds = train_ds.shuffle(1000).batch(BATCH).map(lambda x,y: (vectorizer(x), y)).prefetch(tf.data.AUTOTUNE)

model = models.Sequential([layers.Embedding(MAX_VOCAB, 64),
                           layers.GlobalAveragePooling1D(),
                           layers.Dense(64, activation = "relu"),
                           layers.Dense(num_classes, activation="softmax")
                           ])
model.compile(optimizer= 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])
model.summary()

EPOCHS = 10
model.fit(train_ds, epochs = EPOCHS)

test_headlines = [ "India wins world cup",
                  "NASA discovers new planet",
                   "Stock markets fall due to inflation",
                   "New AI model beats all benchmarks",
                   "Cristiano Ronaldo becomes the topscorer in football history",
                   "Shamikh scores a hattrick in his debut football match",
                   "Planck epoch Institute of Professional studies offers internship to graduated students",
                   "Car crashes due to speeding and 2 people were injured",
                   "A local store victim to a robbery attempt",
                   "Two civilians brutally killed by an armed robber",
                   "Value of Indian ruppee falls to 90 against a US Dollar"]

def clean(s):
  import re
  s = s.lower()
  s = re.sub(r"[^a-z0-9\s]", " ", s)
  return " ".join(s.split())

cleaned_test = [clean(x) for x in test_headlines]

X = vectorizer(cleaned_test)

label_map = {
    0: "Sports",
    1: "Business",
    2: "Economy",
    3: "Science/Technology",
    4: "Crime"
}

pred = model.predict(X)
pred_classes = pred.argmax(axis =1)
predicted_labels = [label_encoder.inverse_transform([cls])[0] for cls in pred_classes]

# Print results
for text, cls in zip(test_headlines, predicted_labels):
    print(f"{text}  --->  {label_map[cls]}")

